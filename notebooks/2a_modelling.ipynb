{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc\\OneDrive\\projects\\Kaggle\\cmi-behavior-sensor-data\\.venv\\Lib\\site-packages\\hyperopt\\atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os, glob\n",
    "import gc\n",
    "import time, math, random\n",
    "import ast\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, KFold, GroupShuffleSplit, GroupKFold, ParameterGrid\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import validation_curve, ValidationCurveDisplay\n",
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from scipy.stats import rankdata\n",
    "from scipy.optimize import dual_annealing\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../scripts'))\n",
    "from cmi_2025 import score\n",
    "from lstm_cnn import LSTMClassifier, LSTMClassifierIMUonly, prepare_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"..\"\n",
    "COMP_DATA_BASE = os.path.join(BASE, \"data\", \"raw\")\n",
    "PREP_DATA_BASE = os.path.join(BASE, \"data\", \"processed\")\n",
    "FIGURES_BASE = os.path.join(BASE, \"figures\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(COMP_DATA_BASE, \"train.csv\")\n",
    "TRAIN_DEMO_PATH = os.path.join(COMP_DATA_BASE, \"train_demographics.csv\")\n",
    "TEST_PATH = os.path.join(COMP_DATA_BASE, \"test.csv\")\n",
    "TEST_DEMO_PATH = os.path.join(COMP_DATA_BASE, \"test_demographics.csv\")\n",
    "\n",
    "features = list(pl.read_csv(TRAIN_PATH).select(pl.all().exclude(\"ID\")).columns)\n",
    "train_ds = pl.read_csv(TRAIN_PATH)\n",
    "train_demo_ds = pl.read_csv(TRAIN_DEMO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc\\OneDrive\\projects\\Kaggle\\cmi-behavior-sensor-data\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id-cols: ['row_id', 'sequence_id', 'sequence_counter', 'subject']\n",
      "acc: ['acc_x', 'acc_y', 'acc_z']\n",
      "rot: ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
      "thm: ['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']\n",
      "tof_1: ['tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63']\n",
      "tof_2: ['tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63']\n",
      "tof_3: ['tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63']\n",
      "tof_4: ['tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63']\n",
      "tof_5: ['tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n",
      "Extra train columns\n",
      "['sequence_type', 'orientation', 'behavior', 'phase', 'gesture']\n",
      "sequence_type:  ['Non-Target', 'Target']\n",
      "orientation:    ['Seated Lean Non Dom - FACE DOWN', 'Lie on Side - Non Dominant', 'Seated Straight', 'Lie on Back']\n",
      "behavior:       ['Moves hand to target location', 'Performs gesture', 'Hand at target location', 'Relaxes and moves hand to target location']\n",
      "phase:          ['Transition', 'Gesture']\n",
      "gesture:        ['Glasses on/off', 'Feel around in tray and pull out an object', 'Neck - pinch skin', 'Write name on leg', 'Forehead - pull hairline', 'Forehead - scratch', 'Pinch knee/leg skin', 'Eyelash - pull hair', 'Pull air toward your face', 'Wave hello', 'Text on phone', 'Eyebrow - pull hair', 'Neck - scratch', 'Above ear - pull hair', 'Write name in air', 'Cheek - pinch skin', 'Scratch knee/leg skin', 'Drink from bottle/cup']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test columns\")\n",
    "test_cols = list(pl.read_csv(TEST_PATH).columns)\n",
    "id_cols = test_cols[:4]\n",
    "acc_cols = [col  for col in test_cols if col.startswith(\"acc\")]\n",
    "rot_cols = [col  for col in test_cols if col.startswith(\"rot\")]\n",
    "thm_cols = [col  for col in test_cols if col.startswith(\"thm\")]\n",
    "tof_cols = [[col  for col in test_cols if col.startswith(f\"tof_{i+1}\")] for i in range(5)]\n",
    "tof_cols_all = [col for cl in tof_cols for col in cl]\n",
    "target_cols = [col for col in train_ds.columns if col not in test_cols]\n",
    "features = acc_cols+rot_cols+thm_cols+[c for cl in tof_cols for c in cl]\n",
    "\n",
    "demo_features = ['adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n",
    "\n",
    "# target\n",
    "gestures = ['Pull air toward your face', 'Feel around in tray and pull out an object', 'Neck - scratch', 'Pinch knee/leg skin', \n",
    "            'Forehead - scratch', 'Eyelash - pull hair', 'Drink from bottle/cup', 'Wave hello', 'Cheek - pinch skin', \n",
    "            'Forehead - pull hairline', 'Text on phone', 'Write name in air', 'Scratch knee/leg skin', 'Neck - pinch skin', \n",
    "            'Write name on leg', 'Above ear - pull hair', 'Eyebrow - pull hair', 'Glasses on/off']\n",
    "le = LabelEncoder()\n",
    "le.fit(gestures)\n",
    "train_ds = train_ds.with_columns(pl.Series(name=\"gesture_id\", values=le.transform(train_ds.select(\"gesture\"))))\n",
    "\n",
    "print(f\"id-cols: {id_cols}\")\n",
    "print(f\"acc: {acc_cols}\")\n",
    "print(f\"rot: {rot_cols}\")\n",
    "print(f\"thm: {thm_cols}\")\n",
    "for i in range(5):\n",
    "    print(f\"tof_{i+1}: {tof_cols[i]}\")\n",
    "    \n",
    "print(f\"Extra train columns\")\n",
    "print(f\"{target_cols}\")\n",
    "for col in target_cols:\n",
    "    print(f\"{col+':':15} {train_ds.select(col).unique().to_series().to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, config, features_dict):\n",
    "    \n",
    "    # Remove Sequence without gesture phase\n",
    "    data = data.filter(pl.col(\"sequence_id\") != 'SEQ_011975')\n",
    "    \n",
    "    # if using all features, remove sequences without thm and tof data (96 in training set)\n",
    "    if not config[\"imu_only\"]:\n",
    "        imu_only_sequences = (data\n",
    "                              .filter(pl.all_horizontal(pl.col(features_dict[\"tof\"] + features_dict[\"thm\"]).is_null()))\n",
    "                              .group_by(\"sequence_id\")\n",
    "                              .agg(pl.col(\"row_id\").len())\n",
    "                              .select(\"sequence_id\")\n",
    "                              .unique())\n",
    "        data = data.filter(~pl.col(\"sequence_id\").is_in(imu_only_sequences.to_series().implode()))\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, data_demo):\n",
    "    sequences = (data\n",
    "                .group_by([\"sequence_id\", \"subject\"])\n",
    "                .agg(pl.col(\"gesture\").first())\n",
    "                )\n",
    "    sgkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    sgkf2 = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    train_index, test_index = next(sgkf.split(sequences, \n",
    "                                            sequences.select(\"gesture\").to_series(), \n",
    "                                            sequences.select(\"subject\").to_series() ))\n",
    "    train_index2, test_index2 = next(sgkf2.split(sequences[test_index], \n",
    "                                            sequences[test_index].select(\"gesture\").to_series(), \n",
    "                                            sequences[test_index].select(\"subject\").to_series() ))\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    for part_name, part_index in zip([\"train\", \"val\", \"test\"], [train_index, train_index2, test_index2]):\n",
    "        data_dict[part_name] = data.filter(pl.col(\"sequence_id\").is_in(sequences[part_index].select(\"sequence_id\").to_series().implode()))\n",
    "        data_dict[part_name + \"_demo\"] = data_demo.filter(pl.col(\"subject\").is_in(sequences[part_index].select(\"subject\").to_series().implode()))\n",
    "        if part_name != 'train':\n",
    "            data_dict[part_name] = data.filter(pl.col(\"sequence_id\").is_in(sequences[test_index][part_index].select(\"sequence_id\").to_series().implode()))\n",
    "            data_dict[part_name + \"_demo\"] = data_demo.filter(pl.col(\"subject\").is_in(sequences[test_index][part_index].select(\"subject\").to_series().implode()))\n",
    "        \n",
    "        \n",
    "        \n",
    "    return data_dict\n",
    "    \n",
    "# train, test = split_dataset(train_ds_prep, with_val=False)\n",
    "# data_dict = split_dataset(train_ds_prep, train_demo_ds_prep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(data):\n",
    "    return (data\n",
    "            .sort(by=\"row_id\")\n",
    "            .with_columns(pl.all().fill_null(strategy=\"forward\").over(\"sequence_id\"))\n",
    "            .with_columns(pl.all().fill_null(strategy=\"backward\").over(\"sequence_id\"))\n",
    "            .with_columns(pl.col(tof_cols_all).fill_null(-1)) \n",
    "            .with_columns(pl.col(thm_cols).fill_null(strategy=\"mean\").over(\"sequence_id\"))\n",
    "            .with_columns(pl.all().fill_null(0))\n",
    "            )\n",
    "    \n",
    "\n",
    "Stats = namedtuple('Stats', ['mean', 'std'])\n",
    "\n",
    "def standardize(data_dict, features=features, demo=False):\n",
    "    train_part, val_part, test_part = \"train\", \"val\", \"test\"\n",
    "    if demo:\n",
    "        train_part, val_part, test_part = \"train_demo\", \"val_demo\", \"test_demo\"\n",
    "\n",
    "    means = data_dict[train_part].select(pl.col(features)).mean().to_dicts()[0]\n",
    "    std = data_dict[train_part].select(pl.col(features)).std().to_dicts()[0]\n",
    "    scaling_dict = {feat: Stats(means[feat], std[feat])   for feat in features}\n",
    "    data_dict[train_part] = data_dict[train_part].with_columns([(pl.col(col)-scaling_dict[col].mean) / scaling_dict[col].std  for col in features])\n",
    "    \n",
    "    if val_part in data_dict and data_dict[val_part] is not None:\n",
    "        data_dict[val_part] = data_dict[val_part].with_columns([(pl.col(col)-scaling_dict[col].mean) / scaling_dict[col].std  for col in features])\n",
    "    \n",
    "    if test_part in data_dict and  data_dict[test_part] is not None:\n",
    "        data_dict[test_part] = data_dict[test_part].with_columns([(pl.col(col)-scaling_dict[col].mean) / scaling_dict[col].std  for col in features])\n",
    "    \n",
    "    return data_dict, scaling_dict\n",
    "\n",
    "# _data is a data dict with part and part_demo datasets\n",
    "def preprocess(_data_dict, features_dict, tail_length=75):\n",
    "    # impute\n",
    "    for part_name in [\"train\", \"val\", \"test\"]:\n",
    "        if part_name in _data_dict:\n",
    "            _data_dict[part_name] = impute(_data_dict[part_name])\n",
    "\n",
    "    # standardize\n",
    "    _data_dict, scaling_dict = standardize(_data_dict, features=features_dict[\"all\"] , demo=False)\n",
    "    \n",
    "    if \"train_demo\" in _data_dict:\n",
    "        _data_dict, scaling_dict_demo = standardize(_data_dict, features=features_dict[\"demo\"] , demo=True)\n",
    "            \n",
    "    return _data_dict, scaling_dict, scaling_dict_demo\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(_data_dict, features_dict, tail_length=75):\n",
    "    \n",
    "    def perpare_part(part, part_demo, tail_length=75):\n",
    "        sequences = {col_name: [] for col_name in [\"acc\", \"rot\", \"thm\", \"tof\", \"target\", \"subject\", \"demo\"]}\n",
    "        for name, data in (part\n",
    "                            .sort(by=['sequence_id', 'sequence_counter'])\n",
    "                            .group_by(\"sequence_id\")\n",
    "                            .tail(tail_length)\n",
    "                            .group_by(\"sequence_id\")\n",
    "                            ):\n",
    "            \n",
    "            \n",
    "            # Take last tail_length sequence parts and impute with null if sequence is not long enough\n",
    "            for col_name in [\"acc\", \"rot\", \"thm\", \"tof\"]:\n",
    "                array = data.select(features_dict[col_name]).to_numpy()\n",
    "                if array.shape[0] < tail_length:\n",
    "                    padding = np.zeros((tail_length -  array.shape[0], array.shape[1]) , dtype=float)\n",
    "                    array = np.vstack((padding, array))\n",
    "                    \n",
    "                sequences[col_name].append(array)\n",
    "            \n",
    "            # Prepare target, subject and demo features\n",
    "            sequences[\"target\"].append(data.select(\"gesture_id\").tail(1).item())\n",
    "            subject = data.select(\"subject\").tail(1).item()\n",
    "            \n",
    "            sequences[\"subject\"].append(subject)\n",
    "            sequences[\"demo\"].append(part_demo.filter(pl.col(\"subject\") == subject).select(features_dict[\"demo\"]).to_numpy())\n",
    "            \n",
    "        return sequences\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    # Prepare each split separately\n",
    "    for part_name in [\"train\", \"val\", \"test\"]:\n",
    "        if part_name not in _data_dict:\n",
    "            continue\n",
    "        \n",
    "        part_data = perpare_part(_data_dict[part_name], _data_dict[part_name + \"_demo\"], tail_length=tail_length)\n",
    "        data[part_name] = {'x_acc': np.array(part_data[\"acc\"]).astype(np.float32), \n",
    "                        'x_rot': np.array(part_data[\"rot\"]).astype(np.float32), \n",
    "                        'x_thm': np.array(part_data[\"thm\"]).astype(np.float32), \n",
    "                        'x_tof': np.array(part_data[\"tof\"]).astype(np.float32), \n",
    "                        'demo': np.array(part_data[\"demo\"]).astype(np.float32),\n",
    "                        'y': np.array(part_data[\"target\"]),\n",
    "                        }\n",
    "    \n",
    "    # Data to torch tensors\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    data_torch = {\n",
    "            part: {'X': torch.as_tensor((np.dstack([(data[part][mtype]) for mtype in [\"x_acc\", \"x_rot\", \"x_thm\", \"x_tof\"]])), device=device),\n",
    "                    'X_demo': torch.as_tensor(data[part][\"demo\"], device=device),\n",
    "                    'y': torch.as_tensor(data[part][\"y\"], device=device) }\n",
    "            for part in data\n",
    "    }\n",
    "    return data_torch\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model_dict, data, config, verbose=False):\n",
    "    model = model_dict[\"model\"]\n",
    "    optimizer = model_dict[\"optimizer\"]\n",
    "    evaluation_mode = model_dict[\"eval_mode\"]\n",
    "    device = model_dict[\"device\"]\n",
    "    grad_scaler = model_dict[\"grad_scaler\"]\n",
    "    amp_enabled = model_dict[\"amp_enabled\"]\n",
    "    amp_dtype = model_dict[\"amp_dtype\"]\n",
    "    target = model_dict[\"target\"]\n",
    "    le = config[\"le\"]\n",
    "    \n",
    "    \n",
    "    @torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
    "    def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "        return (\n",
    "            model(\n",
    "                data[part]['X'][idx],\n",
    "                data[part]['X_demo'][idx]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    task_type = \"classification\"\n",
    "    base_loss_fn = F.mse_loss if task_type == 'regression' else F.cross_entropy\n",
    "\n",
    "\n",
    "    def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "        return base_loss_fn(y_pred, y_true)\n",
    "\n",
    "    def score_fn(y_true, y_pred):\n",
    "        sol = pd.DataFrame({\"gesture\": le.inverse_transform(y_true)}).reset_index(names=[\"id\"])\n",
    "        sub = pd.DataFrame({\"gesture\": le.inverse_transform(y_pred)}).reset_index(names=[\"id\"])\n",
    "        return score(sol, sub, row_id_column_name='id')\n",
    "\n",
    "    @evaluation_mode()\n",
    "    def evaluate(part: str) -> tuple[float, float]:\n",
    "        model.eval()\n",
    "\n",
    "        # When using torch.compile, you may need to reduce the evaluation batch size.\n",
    "        eval_batch_size = 8096\n",
    "        y_pred = (\n",
    "            torch.cat(\n",
    "                [\n",
    "                    apply_model(part, idx)\n",
    "                    for idx in torch.arange(len(data[part]['y']), device=device).split(\n",
    "                        eval_batch_size\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        loss = loss_fn(y_pred, data[part][\"y\"]).detach().cpu().numpy()\n",
    "\n",
    "        if task_type != 'regression':\n",
    "            # For classification, the mean must be computed in the probabily space.\n",
    "            y_pred = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        y_true = data[part]['y'].cpu().numpy()\n",
    "        \n",
    "        sc = (\n",
    "            score_fn(y_true, y_pred.argmax(1))\n",
    "        )\n",
    "        return float(sc), float(loss)  # The higher -- the better.\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Test score before training: {evaluate(\"test\")[0]:.4f}')\n",
    "    \n",
    "    # For demonstration purposes (fast training and bad performance),\n",
    "    # one can set smaller values:\n",
    "    # n_epochs = 20\n",
    "    # patience = 2\n",
    "    n_epochs = 1_000_000_000\n",
    "    if \"n_epochs\" in config:\n",
    "        n_epochs =  config[\"n_epochs\"]\n",
    "    \n",
    "    # Early stopping: the training stops when\n",
    "    # there are more than `patience` consequtive bad updates.\n",
    "    patience = 10\n",
    "    if \"patience\" in config:\n",
    "        patience =  config[\"patience\"]\n",
    "    \n",
    "\n",
    "    batch_size = 256\n",
    "    epoch_size = math.ceil(len(data[\"train\"][\"X\"]) / batch_size)\n",
    "    best = {\n",
    "        'val': -math.inf,\n",
    "        'test': -math.inf,\n",
    "        'epoch': -1,\n",
    "    }\n",
    "    \n",
    "    remaining_patience = patience\n",
    "\n",
    "    if verbose:\n",
    "        print('-' * 88 + '\\n')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # on cpu to save GPU RAM space?\n",
    "            pred_train = torch.zeros((len(data[\"train\"][\"X\"]), config[\"n_classes\"]), device=device)\n",
    "            for batch_idx in tqdm(\n",
    "                torch.randperm(len(data['train']['y']), device=device).split(batch_size),\n",
    "                desc=f'Epoch {epoch}',\n",
    "                total=epoch_size,\n",
    "                disable=not verbose\n",
    "            ):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                pred = apply_model('train', batch_idx)\n",
    "                loss = loss_fn(pred, data[\"train\"][\"y\"][batch_idx])\n",
    "                pred_train[batch_idx] = pred.detach()\n",
    "                if grad_scaler is None:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    grad_scaler.scale(loss).backward()  # type: ignore\n",
    "                    grad_scaler.step(optimizer)\n",
    "                    grad_scaler.update()\n",
    "                    \n",
    "            train_loss = loss_fn(pred_train, data[\"train\"][\"y\"]).cpu().numpy()\n",
    "            train_score = float(score_fn(data[\"train\"][\"y\"].cpu().numpy(), \n",
    "                                         F.softmax(pred_train, dim=1).cpu().numpy().argmax(1)) )\n",
    "            \n",
    "            val_score, val_loss = evaluate('val')\n",
    "            test_score, test_loss = evaluate('test')\n",
    "            if verbose:\n",
    "                print(f'(train) {train_score:.4f} (val) {val_score:.4f} (test) {test_score:.4f}')\n",
    "\n",
    "            mlflow.log_metrics({\"train_loss\": float(train_loss), \"val_loss\": val_loss, \"test_loss\": test_loss,\n",
    "                                \"train_f1-score\": train_score, \"val_f1-score\": val_score, \"test_f1-score\": test_score,  \n",
    "                                }, step=epoch)\n",
    "            \n",
    "            \n",
    "            # if patience is set to 0, don't do early stopping\n",
    "            if (val_score > best['val']) or (patience == 0):\n",
    "                if verbose:\n",
    "                    print('ðŸŒ¸ New best epoch! ðŸŒ¸')\n",
    "                best = {'train': train_score, 'val': val_score, 'test': test_score, 'epoch': epoch}\n",
    "                \n",
    "                # mlflow.pytorch.log_model(pytorch_model=model_dict[\"model\"], \n",
    "                #                          artifact_path=\"\", \n",
    "                #                          registered_model_name=f\"model_{epoch}\",\n",
    "                #                          input_example=data[\"train\"][\"X\"][0,:,:].cpu().numpy())\n",
    "                \n",
    "                \n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "        \n",
    "        mlflow.log_metrics({ \"best_train_score\": best[\"train\"], \"best_val_score\": best[\"val\"], \"best_test_score\": best[\"test\"], \n",
    "                              \"best_epoch\": best[\"epoch\"] })\n",
    "        if verbose:\n",
    "            print('\\n\\nResult:')\n",
    "            print(best)\n",
    "    return best\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning...\n",
      "Splitting data...\n",
      "Preprocessing...\n",
      "Preparing dataset...\n",
      "Preparing model...\n",
      "Device:        CUDA\n",
      "AMP:           False (dtype: torch.bfloat16)\n",
      "torch.compile: False\n",
      "Training model...\n",
      "Test score before training: 0.2893\n",
      "----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eabadbbb9c84b548fbcac27b7ee8447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.4208 (val) 0.4495 (test) 0.4473\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cd4de851054f6b8baa07fdc61a88c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.4828 (val) 0.4954 (test) 0.4814\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e4e0cdb62743f997710cabe39d24b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.4968 (val) 0.5061 (test) 0.4984\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50391b4b1c134e149e8a5db6f5506fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5116 (val) 0.5132 (test) 0.5138\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ed8057998a483bb67fce8d3f326da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5222 (val) 0.5185 (test) 0.5350\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7524282a65594c4b84f200829a628273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5342 (val) 0.5379 (test) 0.5545\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf1960fff7a4a6aba8aa77fe327ba5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5506 (val) 0.5618 (test) 0.5486\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208efdfd8b7a485c8c65df64e687967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5630 (val) 0.5823 (test) 0.5630\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96224663df8849a1b82a12d8055e4a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5771 (val) 0.5894 (test) 0.5804\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78eeb4c7c57a4de494625ac42ed0b1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5866 (val) 0.5623 (test) 0.5459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54828ba6b0414fdd96ad6aa0818aee08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.5829 (val) 0.5993 (test) 0.5662\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6637ca2155f411aabc565dbef74de8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6036 (val) 0.6098 (test) 0.6026\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5925027ecc468ebaa611dc57d75c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6095 (val) 0.6288 (test) 0.6129\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1677060bba4f51be0f0d72a9c27697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6243 (val) 0.6389 (test) 0.6141\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da24d6c3a88f414a99097fd6a9a614d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6191 (val) 0.6013 (test) 0.5660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a600ef60aa4841a5a7dbbfa6ca0c387e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6220 (val) 0.6308 (test) 0.6222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb0e13a3c304561a7063fe0afdfcd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6404 (val) 0.6526 (test) 0.6251\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3189d6962974ba0a16f6a1c2ad41131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6402 (val) 0.6434 (test) 0.6094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ff2990325d445594a68dba874c634f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6439 (val) 0.6508 (test) 0.6254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d4eeae70b54fd0a448a8bcf803d59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6510 (val) 0.6588 (test) 0.6284\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5324a1296d1490586c218e3e2e48691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6622 (val) 0.6607 (test) 0.6409\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539e41f225104ee6a72c752481b5493c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6558 (val) 0.6577 (test) 0.6341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f17367a1884c32a474b2aedde48701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6627 (val) 0.6605 (test) 0.6325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0489c1f4ddb4720a079c29b02974043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6593 (val) 0.6643 (test) 0.6354\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2ae071a3f14d638f1083b75b522b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6694 (val) 0.6634 (test) 0.6294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1d6602303a451faf25be5244338952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6710 (val) 0.6809 (test) 0.6597\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67b54a888ca4022bcfb51d1a4d308b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6761 (val) 0.6895 (test) 0.6473\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dd89c984494c78ba5f55e052e2c9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6893 (val) 0.6924 (test) 0.6571\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe91f376fc4b4dd6845675af920df460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6896 (val) 0.6822 (test) 0.6469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d1b7ed113c4393b4ed7eae3dde5fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6852 (val) 0.6945 (test) 0.6499\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c17347f46b406b94b9c80200147a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6718 (val) 0.6949 (test) 0.6369\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfea851433646d99eb481368d706d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6806 (val) 0.6872 (test) 0.6486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40db68977f24f43b1b7ab804c1e59de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6706 (val) 0.6889 (test) 0.6443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f058a49c84614e3199b527aea5ca19e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6985 (val) 0.6967 (test) 0.6365\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1c4455ae834d5fa28e01ddbcc1bff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6867 (val) 0.6829 (test) 0.6516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c56a52787245c884e507793a4ffbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6999 (val) 0.6982 (test) 0.6660\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a5fa59ff9c40b39a64af16d6ae63f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7161 (val) 0.7103 (test) 0.6719\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd759dad0283484eb15ec6a56bf1f3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7177 (val) 0.7013 (test) 0.6524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5877daf10d44d9ac9971a97b50c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7139 (val) 0.6873 (test) 0.6575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e373ebbe7e4d4b71b8a3c8e84b307bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6854 (val) 0.6901 (test) 0.6280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb2191682bf4020b206237bc0cb234a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.6939 (val) 0.7066 (test) 0.6605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44de3ca7f0747a086d81a982e65d370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7174 (val) 0.7241 (test) 0.6815\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2054069cd5064dd2bf9f37a6a9f4a5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7303 (val) 0.7009 (test) 0.6507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026559711b3b41fe8bb1574143ff5cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7348 (val) 0.7002 (test) 0.6707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f0aeaca17a4edfa06794e56714dd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7402 (val) 0.7224 (test) 0.6772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c49a083b64a43eebce201d9c4b82552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7381 (val) 0.7196 (test) 0.6810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c580ff40576450cbbf3a0dd13c732cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7548 (val) 0.7344 (test) 0.6889\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f466169c6dd1491793e1fed0d278cf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7448 (val) 0.7235 (test) 0.6955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd3883f48c54ecf85b3675baf2eadd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7302 (val) 0.7304 (test) 0.6753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a25b17c2f54573967c5db586a3f112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7395 (val) 0.7198 (test) 0.6721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6085c3954643d2afbd4bb9a98738dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7601 (val) 0.7317 (test) 0.6943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5b38204e324e1d9e6eb5fbef4e33cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7616 (val) 0.7376 (test) 0.6883\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27aadc10982490391c4ad905d18448e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7514 (val) 0.7258 (test) 0.6841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164b0e5952e44f7198b830264c6a33e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7448 (val) 0.7232 (test) 0.6691\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95537ab8a9fb479490db4d436ede844b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7513 (val) 0.7279 (test) 0.6789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989c8c6e02294382a8059f905307c412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7724 (val) 0.7300 (test) 0.6901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86eb7f40bd314d6faecdda841d70e2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7714 (val) 0.7382 (test) 0.6872\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec99dc7ce6814fb4913aa2a8986fbd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7709 (val) 0.7163 (test) 0.6601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46991ad331b473f81b38e43f7c9fa6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7750 (val) 0.7398 (test) 0.6904\n",
      "ðŸŒ¸ New best epoch! ðŸŒ¸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f13df8b8a94391a31eff71c625f5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) 0.7621 (val) 0.7277 (test) 0.6750\n",
      "\n",
      "\n",
      "Result:\n",
      "{'train': 0.7750122332451037, 'val': 0.7397669890235561, 'test': 0.6904332694601707, 'epoch': 58}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.7750122332451037,\n",
       " 'val': 0.7397669890235561,\n",
       " 'test': 0.6904332694601707,\n",
       " 'epoch': 58}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class LSTM_Validator():\n",
    "    def __init__(self, train_ds, train_demo_ds, config, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.model_dict = None\n",
    "        train_cols = list(train_ds.columns)\n",
    "        acc_cols = [col  for col in train_cols if col.startswith(\"acc\")]\n",
    "        rot_cols = [col  for col in train_cols if col.startswith(\"rot\")]\n",
    "        thm_cols = [col  for col in train_cols if col.startswith(\"thm\")]\n",
    "        tof_cols = [[col  for col in train_cols if col.startswith(f\"tof_{i+1}\")] for i in range(5)]\n",
    "        tof_cols_all = [col for cl in tof_cols for col in cl]\n",
    "        self.features_dict = {\"acc\":acc_cols, \"rot\":rot_cols, \"thm\":thm_cols, \"tof\":tof_cols_all}\n",
    "        self.features = acc_cols+rot_cols+thm_cols+tof_cols_all\n",
    "        gestures = ['Pull air toward your face', 'Feel around in tray and pull out an object', 'Neck - scratch', 'Pinch knee/leg skin', \n",
    "                'Forehead - scratch', 'Eyelash - pull hair', 'Drink from bottle/cup', 'Wave hello', 'Cheek - pinch skin', \n",
    "                'Forehead - pull hairline', 'Text on phone', 'Write name in air', 'Scratch knee/leg skin', 'Neck - pinch skin', \n",
    "                'Write name on leg', 'Above ear - pull hair', 'Eyebrow - pull hair', 'Glasses on/off']\n",
    "        \n",
    "        self.demo_features = ['adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n",
    "        self.features_dict[\"demo\"] = self.demo_features\n",
    "        self.features_dict[\"all\"] = acc_cols+rot_cols+thm_cols+tof_cols_all\n",
    "        \n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(gestures)\n",
    "        train_ds = train_ds.with_columns(pl.Series(name=\"gesture_id\", values=self.le.transform(train_ds.select(\"gesture\").to_series())))\n",
    "\n",
    "        self.CONFIG = config\n",
    "        \n",
    "        self.CONFIG[\"n_demo_features\"] = len(self.demo_features)\n",
    "        self.CONFIG[\"n_classes\"] = len(self.le.classes_)\n",
    "        self.CONFIG[\"le\"] = self.le\n",
    "        \n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Cleaning...\")\n",
    "        data = clean_data(train_ds, self.CONFIG, self.features_dict)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Splitting data...\")\n",
    "        data_dict = split_data(data, train_demo_ds)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Preprocessing...\")\n",
    "        data_dict, self.ct, self.ct_demo = preprocess(data_dict, self.features_dict)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Preparing dataset...\")\n",
    "        self.data = create_dataset(data_dict, features_dict=self.features_dict, tail_length=self.CONFIG[\"tail_length\"])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    # PATH: Path to save model to, e.g. 'model.pth'\n",
    "    def train_model(self, hyper_params, PATH=None):\n",
    "        self.hyper_params=hyper_params\n",
    "        \n",
    "        if self.model_dict:\n",
    "            del self.model_dict[\"model\"]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache() \n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Preparing model...\")\n",
    "        self.model_dict = prepare_model(config=self.CONFIG | self.hyper_params)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Training model...\")\n",
    "            \n",
    "        best = train(self.model_dict, self.data, self.CONFIG | self.hyper_params, verbose=self.verbose)\n",
    "        \n",
    "        if PATH is not None:\n",
    "            if self.verbose:\n",
    "                print(\"Saving model...\")\n",
    "            torch.save(self.model_dict[\"model\"].state_dict(), PATH)\n",
    "        \n",
    "        return best\n",
    "        \n",
    "    # PATH: saved model path, e.g. 'model.pth'\n",
    "    def load_model(self, PATH):\n",
    "        if self.verbose:\n",
    "            print(\"Loading model...\")\n",
    "        \n",
    "        if not self.model_dict:\n",
    "            self.model_dict = prepare_model(config=self.CONFIG | self.hyper_params)\n",
    "        \n",
    "        if self.model_dict[\"device\"].type == 'cpu':  \n",
    "            self.model_dict[\"model\"].load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
    "        else:\n",
    "            self.model_dict[\"model\"].load_state_dict(torch.load(PATH))\n",
    "   \n",
    "    \n",
    "\n",
    "CONFIG = {\n",
    "    \"compile_model\": False,\n",
    "    \n",
    "    \"n_features\": 332,\n",
    "    \"target\": \"gesture_id\",\n",
    "    \"tail_length\": 100,\n",
    "    \"imu_only\": False\n",
    "}\n",
    "\n",
    "hyper_params = {\n",
    "    \"lstm_layers\": 2,\n",
    "    \"hidden_size\": 64,\n",
    "    'dropout': 0.2,\n",
    "    \"learning_rate\": 1e-3, \n",
    "    \"weight_decay\": 0.9,\n",
    "    \"n_epochs\": 60,\n",
    "    \"patience\": 84\n",
    "}\n",
    "\n",
    "lstm_val = LSTM_Validator(train_ds, train_demo_ds, CONFIG, verbose=True)\n",
    "lstm_val.train_model(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(f\"CMI LSTM Experiment {pd.Timestamp.now()}\")\n",
    "metrics = pl.DataFrame()\n",
    "for i in range(5):\n",
    "    print(f\"FOLD {i}\")\n",
    "    data = load_fold(i, prefix=\"20250628_v2\")\n",
    "    data[\"test\"] = data[\"val\"]\n",
    "\n",
    "    model_dict = prepare_model(config=CONFIG | hyper_params)\n",
    "\n",
    "    best = train(model_dict, data, CONFIG | hyper_params, verbose=True)\n",
    "    print(best)\n",
    "    metrics = pl.concat([metrics, pl.DataFrame(best)])\n",
    "    \n",
    "    data.clear()\n",
    "    model_dict.clear() \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "print(metrics)\n",
    "print(metrics.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "def test_LSTM():\n",
    "    # The first axis is the sequence itself, \n",
    "    # the second indexes instances in the mini-batch, \n",
    "    # and the third indexes elements of the input.\n",
    "    lstm = nn.LSTM(3, 3)\n",
    "    # initialize the hidden state.\n",
    "    hidden = (torch.randn(1, 2, 3),\n",
    "            torch.randn(1, 2, 3))\n",
    "\n",
    "    sample1 = [torch.randn(1, 3) for _ in range(5)] \n",
    "    sample2 = [torch.randn(1, 3) for _ in range(5)] \n",
    "    sample1 = torch.cat(sample1).view(len(sample1), 1, -1)\n",
    "    sample2 = torch.cat(sample2).view(len(sample2), 1, -1)\n",
    "    inputs = torch.hstack([sample1, sample2])\n",
    "    print(inputs.shape)\n",
    "    print(inputs)\n",
    "    # inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out, hidden = lstm(inputs, hidden)\n",
    "    display(out.shape)\n",
    "    display(hidden)\n",
    "    \n",
    "# test_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # stack it together for now\n",
    "    data = {\n",
    "            part: {'X': torch.as_tensor((np.dstack([(data_prep[\"train\"][mtype]) for mtype in [\"x_acc\", \"x_rot\", \"x_thm\", \"x_tof\"]])), device=device) }\n",
    "            for part in data_prep\n",
    "    }\n",
    "    for part in data_prep:\n",
    "        data[part]['y'] = torch.as_tensor(data_prep[\"train\"][\"y\"], device=device) \n",
    "        \n",
    "    # np.dstack([(data_prep[\"train\"][mtype]) for mtype in [\"x_acc\", \"x_rot\", \"x_thm\", \"x_tof\"]])\n",
    "    # data_prep[\"train\"][\"x_acc\"]\n",
    "    BATCH_SIZE = 10\n",
    "    TAIL_LENGTH = 75\n",
    "    idx = np.random.randint(low=0, high=5000, size=BATCH_SIZE)\n",
    "    print(data[\"train\"][\"X\"][idx].shape)\n",
    "\n",
    "    print(torch.transpose(data[\"train\"][\"X\"][idx], 0,1).shape)\n",
    "    print(data[\"train\"][\"X\"][idx].view(TAIL_LENGTH, BATCH_SIZE, -1).shape)\n",
    "    print(torch.transpose(data[\"train\"][\"X\"][idx], 0,1))\n",
    "    print(torch.transpose(data[\"train\"][\"X\"][idx], 1,0))\n",
    "    print(data[\"train\"][\"X\"][idx].view(TAIL_LENGTH, BATCH_SIZE, -1))\n",
    "    \n",
    "    NUM_LAYERS = 1\n",
    "    HIDDEN_SIZE = 32\n",
    "\n",
    "\n",
    "    class LSTMClassifier(nn.Module):\n",
    "\n",
    "        def __init__(self, input_dim, hidden_dim, classes_dim, num_layers, dropout_rate=0):\n",
    "            super(LSTMClassifier, self).__init__()\n",
    "            self.hidden_dim = hidden_dim\n",
    "\n",
    "            # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "            # with dimensionality hidden_dim.\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, dropout=dropout_rate)\n",
    "\n",
    "            # The linear layer that maps from hidden state space to tag space\n",
    "            self.hidden2class = nn.Linear(hidden_dim, classes_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            class_space = self.hidden2class(lstm_out[-1,...])\n",
    "            class_scores = F.softmax(class_space, dim=1)\n",
    "            return class_scores\n",
    "\n",
    "\n",
    "    model = LSTMClassifier(332 , hidden_dim=HIDDEN_SIZE, classes_dim=len(le.classes_), num_layers=NUM_LAYERS , dropout_rate=0)\n",
    "\n",
    "    idx = np.random.randint(low=0, high=5000, size=BATCH_SIZE)\n",
    "    # output (L,N,Dâˆ—H): L=sequence length,  N=Batch size, H=Hiddensize\n",
    "    # hidden size (Dâˆ—num_layers,N,H): num_layers, N=Batch Size, H=hidden_size\n",
    "    def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "        return (\n",
    "            model(\n",
    "                torch.transpose(data[part]['X'][idx],0,1)\n",
    "            )\n",
    "        )\n",
    "    print(apply_model(\"train\", idx).shape)\n",
    "    print(apply_model(\"train\", idx))\n",
    "\n",
    "    # torch.cat([torch.as_tensor(data_prep[\"train\"][mtype][idx]) for mtype in [\"x_acc\", \"x_rot\", \"x_thm\", \"x_tof\"]])\n",
    " \n",
    "# test_model()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:        CUDA\n",
      "AMP:           False (dtype: torch.bfloat16)\n",
      "torch.compile: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc\\OneDrive\\projects\\Kaggle\\cmi-behavior-sensor-data\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'model': LSTMClassifier(\n",
       "    (lstm): LSTM(332, 32, dropout=0.1)\n",
       "    (hidden2class): Linear(in_features=32, out_features=18, bias=True)\n",
       "  ),\n",
       "  'eval_mode': torch.autograd.grad_mode.inference_mode,\n",
       "  'optimizer': AdamW (\n",
       "  Parameter Group 0\n",
       "      amsgrad: False\n",
       "      betas: (0.9, 0.999)\n",
       "      capturable: False\n",
       "      differentiable: False\n",
       "      eps: 1e-08\n",
       "      foreach: None\n",
       "      fused: None\n",
       "      lr: 0.002\n",
       "      maximize: False\n",
       "      weight_decay: 0.0003\n",
       "  ),\n",
       "  'device': device(type='cuda', index=0),\n",
       "  'grad_scaler': None,\n",
       "  'amp_enabled': False,\n",
       "  'amp_dtype': torch.bfloat16,\n",
       "  'target': 'gesture_id'},\n",
       " {'train': {'X': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.6403,  0.7623,  1.0088,  ...,  1.1836,  1.1813,  1.1942],\n",
       "            [ 0.7338,  0.7855,  0.8770,  ...,  1.1346,  1.1467,  1.1764],\n",
       "            [ 0.9208,  0.8539,  0.7325,  ...,  1.0693,  1.1467,  1.1764]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.2786,  1.2716,  0.6154,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.3121,  1.1140,  0.8540,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.0093,  0.6023,  0.8924,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-1.7876,  0.4509, -0.5867,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.8203,  0.3973, -0.7754,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.3788,  0.5728, -0.6999,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.3779, -0.4670,  0.1324,  ..., -0.1063, -0.0629, -0.0368],\n",
       "            [ 1.3732, -0.4600,  0.1388,  ..., -0.0736, -0.0801, -0.0547],\n",
       "            [ 1.3732, -0.4600,  0.1388,  ..., -0.1226, -0.0629, -0.0190],\n",
       "            ...,\n",
       "            [-1.6593,  0.9719, -0.4511,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.6122,  0.9036, -0.4568,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.5385,  0.9036, -0.4447,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           [[ 0.4458, -0.5097,  1.5404,  ...,  0.9713,  1.1813,  1.3905],\n",
       "            [ 0.4929, -0.5252,  1.5219,  ...,  0.9713,  1.1294,  1.3013],\n",
       "            [ 0.5127, -0.5097,  1.5212,  ...,  1.0203,  1.1467,  1.3905],\n",
       "            ...,\n",
       "            [-1.9104, -0.7993, -0.2668,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.8224, -1.2870, -0.2355,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.9363, -1.1651, -0.1977,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 1.0743,  0.8842,  0.0377,  ...,  1.8530,  1.7342,  1.5867],\n",
       "            [ 1.0531,  0.8764,  0.1132,  ...,  1.9346,  1.7170,  1.6224],\n",
       "            [ 1.0074,  0.8912,  0.1509,  ...,  1.9673,  1.8898, -0.5185]]],\n",
       "          device='cuda:0'),\n",
       "   'y': tensor([ 1,  6,  1,  ..., 14,  0,  1], device='cuda:0')},\n",
       "  'val': {'X': tensor([[[-1.3734, -0.3497,  0.5936,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.2267, -0.1828,  1.1899,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-1.8490, -0.4336,  1.1521,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            ...,\n",
       "            [ 1.2353,  0.8834,  1.1208,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.6112,  1.1117,  0.7069,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.0780,  1.1280,  1.2462,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           [[-0.3314, -0.2426,  1.6690,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.1103, -0.2806,  1.6684,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.2311, -0.2729,  1.6690,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            ...,\n",
       "            [-1.0731, -0.5695, -1.6256,  ..., -0.5471, -0.5294,  0.2486],\n",
       "            [-0.9257, -0.5540, -1.0179,  ..., -0.5471,  0.0581,  0.0881],\n",
       "            [-0.9790, -0.5314, -1.3121,  ...,  0.1223,  0.1445,  0.2308]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 1.2510, -0.6665,  0.7881,  ...,  1.5917,  1.6824,  2.1755],\n",
       "            ...,\n",
       "            [ 1.2176, -0.7193,  0.8009,  ...,  1.5264,  1.5787,  1.7294],\n",
       "            [ 1.1841, -0.7271,  0.8073,  ...,  1.5264,  1.5269,  1.7473],\n",
       "            [ 1.1780, -0.7271,  0.8131,  ...,  1.5591,  1.5614,  1.7473]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 0.5598, -0.8296,  1.4432,  ...,  2.0326,  2.2008,  2.6215],\n",
       "            [ 0.5871, -0.8296,  1.4374,  ...,  2.0163,  2.2008,  2.6750],\n",
       "            [ 0.5871, -0.8063,  1.4317,  ...,  1.9836,  2.2181,  2.6215],\n",
       "            ...,\n",
       "            [-0.0114,  1.1847, -1.0063,  ..., -0.5471, -0.5294,  0.1416],\n",
       "            [-0.0182,  1.1474, -0.8995,  ..., -0.5471,  0.3346,  0.1416],\n",
       "            [ 0.3633,  1.3081, -0.9123,  ...,  0.4652,  0.3864,  0.2665]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.0855,  1.2848, -0.7082,  ...,  1.3468,  1.2850,  0.8731],\n",
       "            [ 0.0521,  1.3679, -0.7274,  ...,  1.3632,  1.3195,  0.8552],\n",
       "            [ 0.0521,  1.2685, -0.7716,  ...,  1.3468,  1.2158,  0.8017]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.9542,  1.0224,  0.3301,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.8662,  0.9688,  0.4299,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.9794,  0.9843,  0.3358,  ..., -0.5471, -0.5294, -0.5185]]],\n",
       "          device='cuda:0'),\n",
       "   'y': tensor([15, 10, 14,  ...,  9,  3,  9], device='cuda:0')},\n",
       "  'test': {'X': tensor([[[-1.8981, -0.7442,  0.5821,  ..., -0.4655, -0.5294,  0.7660],\n",
       "            [-1.8442, -0.8281,  0.1055,  ..., -0.4002, -0.5294, -0.5185],\n",
       "            [-1.7644, -0.9803, -0.8541,  ..., -0.4002, -0.5294, -0.5185],\n",
       "            ...,\n",
       "            [-2.0448,  0.1768,  0.3755,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-2.0987,  0.2917,  0.3377,  ..., -0.4328, -0.5294, -0.5185],\n",
       "            [-1.7712,  0.4128, -0.0448,  ..., -0.3675, -0.5294,  0.9980]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.9779, -0.6968,  0.1126,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            ...,\n",
       "            [-0.2051,  1.1257, -1.1285,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.2918,  1.2476, -0.5828,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.3123,  1.2864, -0.8208,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           [[ 0.3728, -0.7644,  1.5168,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [ 0.3926, -0.7799,  1.5097,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [ 0.3994, -0.7644,  1.5104,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            ...,\n",
       "            [-1.8892, -0.8863,  0.5879,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [-1.8899, -0.3458,  0.4433,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [-1.9295, -0.9166,  0.5687,  ..., -0.5308, -0.5121, -0.5007]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 0.7972, -0.3622,  1.2794,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [ 0.8109, -0.4150,  1.3037,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [ 0.7440, -0.3769,  1.3236,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            ...,\n",
       "            [ 0.7843, -0.6588, -1.2104,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [ 0.6499, -0.7349, -1.2686,  ..., -0.5308, -0.5121, -0.5007],\n",
       "            [ 0.7304, -0.6821, -1.2731,  ..., -0.5308, -0.5121, -0.5007]],\n",
       "   \n",
       "           [[ 0.8027, -0.9997,  1.1649,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.7959, -0.9764,  1.1841,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.8027, -0.9764,  1.1771,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            ...,\n",
       "            [-0.4419,  1.5753, -0.4664,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.4290,  1.5209, -0.5477,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [-0.3751,  1.5442, -0.5042,  ..., -0.5471, -0.5294, -0.5185]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.2063, -0.2923, -1.1484,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.3605, -0.4072, -1.4241,  ..., -0.5471, -0.5294, -0.5185],\n",
       "            [ 0.4138, -0.5213, -1.5130,  ..., -0.5471, -0.5294, -0.5185]]],\n",
       "          device='cuda:0'),\n",
       "   'y': tensor([ 6,  6,  9,  ..., 11, 10, 17], device='cuda:0')}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LAYERS = 1\n",
    "HIDDEN_SIZE = 32\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"compile_model\": False,\n",
    "    \n",
    "    \"n_features\": 332,\n",
    "    \"n_classes\": len(le.classes_),\n",
    "    \"target\": \"gesture_id\"\n",
    "}\n",
    "\n",
    "hyper_params = {\n",
    "    \"lstm_layers\": 1,\n",
    "    \"hidden_size\": 32,\n",
    "    'dropout': 0.1,\n",
    "    \"learning_rate\": 2e-3, \n",
    "    \"weight_decay\": 3e-4,\n",
    "}\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, classes_dim, num_layers, dropout_rate=0):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, dropout=dropout_rate)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2class = nn.Linear(hidden_dim, classes_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        class_space = self.hidden2class(lstm_out[-1,...])\n",
    "        # class_scores = F.softmax(class_space, dim=1)\n",
    "        return class_space\n",
    "    \n",
    "\n",
    "\n",
    "def prepare_model(data_prep, config):\n",
    "    # Device\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Convert data to tensors\n",
    "    # stack it together for now\n",
    "    data = {\n",
    "        part: {'X': torch.as_tensor((np.dstack([(data_prep[part][mtype]) for mtype in [\"x_acc\", \"x_rot\", \"x_thm\", \"x_tof\"]])), device=device) }\n",
    "        for part in data_prep\n",
    "    }\n",
    "\n",
    "    for part in data_prep:\n",
    "        data[part]['y'] = torch.as_tensor(data_prep[part][\"y\"], device=device) \n",
    "\n",
    "\n",
    "    # Automatic mixed precision (AMP)\n",
    "    # torch.float16 is implemented for completeness,\n",
    "    # but it was not tested in the project,\n",
    "    # so torch.bfloat16 is used by default.\n",
    "    amp_dtype = (\n",
    "        torch.bfloat16\n",
    "        if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "        else torch.float16\n",
    "        if torch.cuda.is_available()\n",
    "        else None\n",
    "    )\n",
    "    # Changing False to True will result in faster training on compatible hardware.\n",
    "    amp_enabled = False and amp_dtype is not None\n",
    "    grad_scaler = torch.amp.GradScaler(\"cuda\") if amp_dtype is torch.float16 else None  # type: ignore\n",
    "\n",
    "    # torch.compile\n",
    "    compile_model = config[\"compile_model\"]\n",
    "\n",
    "    # fmt: off\n",
    "    print(\n",
    "        f'Device:        {device.type.upper()}'\n",
    "        f'\\nAMP:           {amp_enabled} (dtype: {amp_dtype})'\n",
    "        f'\\ntorch.compile: {compile_model}'\n",
    "    )\n",
    "    \n",
    "    # Choose one of the two configurations below.\n",
    "    # TODO\n",
    "    model = LSTMClassifier(config[\"n_features\"], config[\"hidden_size\"], config[\"n_classes\"], config[\"lstm_layers\"], config[\"dropout\"]).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    if compile_model:\n",
    "        # NOTE\n",
    "        # `torch.compile` is intentionally called without the `mode` argument\n",
    "        # (mode=\"reduce-overhead\" caused issues during training with torch==2.0.1).\n",
    "        model = torch.compile(model)\n",
    "        evaluation_mode = torch.no_grad\n",
    "    else:\n",
    "        evaluation_mode = torch.inference_mode\n",
    "        \n",
    "    model_dict = {\"model\": model,\n",
    "                  \"eval_mode\": evaluation_mode,\n",
    "                  \"optimizer\": optimizer,\n",
    "                  \"device\": device,\n",
    "                  \"grad_scaler\": grad_scaler,\n",
    "                  \"amp_enabled\": amp_enabled,\n",
    "                  \"amp_dtype\": amp_dtype,\n",
    "                  \"target\": config[\"target\"]\n",
    "                  }\n",
    "        \n",
    "    return model_dict, data\n",
    "\n",
    "prepare_model(data_prep, CONFIG | hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc\\OneDrive\\projects\\Kaggle\\cmi-behavior-sensor-data\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "2025/06/23 19:59:45 INFO mlflow.tracking.fluent: Experiment with name 'CMI LSTM Experiment 2025-06-23 19:59:45.708743' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:        CUDA\n",
      "AMP:           False (dtype: torch.bfloat16)\n",
      "torch.compile: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.8777034604580647,\n",
       " 'val': 0.6870461894341058,\n",
       " 'test': 0.6734010885145207,\n",
       " 'epoch': 28}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train(model_dict, data, config, verbose=False):\n",
    "    model = model_dict[\"model\"]\n",
    "    optimizer = model_dict[\"optimizer\"]\n",
    "    evaluation_mode = model_dict[\"eval_mode\"]\n",
    "    device = model_dict[\"device\"]\n",
    "    grad_scaler = model_dict[\"grad_scaler\"]\n",
    "    amp_enabled = model_dict[\"amp_enabled\"]\n",
    "    amp_dtype = model_dict[\"amp_dtype\"]\n",
    "    target = model_dict[\"target\"]\n",
    "    \n",
    "    \n",
    "    @torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
    "    def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "        return (\n",
    "            model(\n",
    "                torch.transpose(data[part]['X'][idx],0,1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    task_type = \"classification\"\n",
    "    base_loss_fn = F.mse_loss if task_type == 'regression' else F.cross_entropy\n",
    "\n",
    "\n",
    "    def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "        return base_loss_fn(y_pred, y_true)\n",
    "\n",
    "    # TODO: Replace with competition metric\n",
    "    def score_fn(y_true, y_pred):\n",
    "        sol = pd.DataFrame({\"gesture\": le.inverse_transform(y_true)}).reset_index(names=[\"id\"])\n",
    "        sub = pd.DataFrame({\"gesture\": le.inverse_transform(y_pred)}).reset_index(names=[\"id\"])\n",
    "        return score(sol, sub, row_id_column_name='id')\n",
    "\n",
    "    @evaluation_mode()\n",
    "    def evaluate(part: str) -> tuple[float, float]:\n",
    "        model.eval()\n",
    "\n",
    "        # When using torch.compile, you may need to reduce the evaluation batch size.\n",
    "        eval_batch_size = 8096\n",
    "        y_pred = (\n",
    "            torch.cat(\n",
    "                [\n",
    "                    apply_model(part, idx)\n",
    "                    for idx in torch.arange(len(data[part]['y']), device=device).split(\n",
    "                        eval_batch_size\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        loss = loss_fn(y_pred, data[part][\"y\"]).detach().cpu().numpy()\n",
    "\n",
    "        if task_type != 'regression':\n",
    "            # For classification, the mean must be computed in the probabily space.\n",
    "            y_pred = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        y_true = data[part]['y'].cpu().numpy()\n",
    "        \n",
    "        sc = (\n",
    "            score_fn(y_true, y_pred.argmax(1))\n",
    "        )\n",
    "        return float(sc), float(loss)  # The higher -- the better.\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Test score before training: {evaluate(\"test\")[0]:.4f}')\n",
    "    \n",
    "    # For demonstration purposes (fast training and bad performance),\n",
    "    # one can set smaller values:\n",
    "    # n_epochs = 20\n",
    "    # patience = 2\n",
    "    n_epochs = 1_000_000_000\n",
    "    if \"n_epochs\" in config:\n",
    "        n_epochs =  config[\"n_epochs\"]\n",
    "    \n",
    "    # Early stopping: the training stops when\n",
    "    # there are more than `patience` consequtive bad updates.\n",
    "    patience = 10\n",
    "    if \"patience\" in config:\n",
    "        patience =  config[\"patience\"]\n",
    "    \n",
    "\n",
    "    batch_size = 256\n",
    "    epoch_size = math.ceil(len(data[\"train\"][\"X\"]) / batch_size)\n",
    "    best = {\n",
    "        'val': -math.inf,\n",
    "        'test': -math.inf,\n",
    "        'epoch': -1,\n",
    "    }\n",
    "    \n",
    "    remaining_patience = patience\n",
    "\n",
    "    if verbose:\n",
    "        print('-' * 88 + '\\n')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            pred_train = torch.zeros((len(data[\"train\"][\"X\"]), config[\"n_classes\"]), device=device)\n",
    "            for batch_idx in tqdm(\n",
    "                torch.randperm(len(data['train']['y']), device=device).split(batch_size),\n",
    "                desc=f'Epoch {epoch}',\n",
    "                total=epoch_size,\n",
    "                disable=not verbose\n",
    "            ):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                pred = apply_model('train', batch_idx)\n",
    "                loss = loss_fn(pred, data[\"train\"][\"y\"][batch_idx])\n",
    "                pred_train[batch_idx] = pred.detach()\n",
    "                if grad_scaler is None:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    grad_scaler.scale(loss).backward()  # type: ignore\n",
    "                    grad_scaler.step(optimizer)\n",
    "                    grad_scaler.update()\n",
    "                    \n",
    "            train_loss = loss_fn(pred_train, data[\"train\"][\"y\"]).cpu().numpy()\n",
    "            train_score = float(score_fn(data[\"train\"][\"y\"].cpu().numpy(), \n",
    "                                         F.softmax(pred_train, dim=1).cpu().numpy().argmax(1)) )\n",
    "            \n",
    "            val_score, val_loss = evaluate('val')\n",
    "            test_score, test_loss = evaluate('test')\n",
    "            if verbose:\n",
    "                print(f'(val) {val_score:.4f} (test) {test_score:.4f}')\n",
    "\n",
    "            mlflow.log_metrics({\"train_loss\": float(train_loss), \"val_loss\": val_loss, \"test_loss\": test_loss,\n",
    "                                \"train_f1-score\": train_score, \"val_f1-score\": val_score, \"test_f1-score\": test_score,  \n",
    "                                }, step=epoch)\n",
    "            \n",
    "            \n",
    "            # if patience is set to 0, don't do early stopping\n",
    "            if (val_score > best['val']) or (patience == 0):\n",
    "                if verbose:\n",
    "                    print('ðŸŒ¸ New best epoch! ðŸŒ¸')\n",
    "                best = {'train': train_score, 'val': val_score, 'test': test_score, 'epoch': epoch}\n",
    "                \n",
    "                # mlflow.pytorch.log_model(pytorch_model=model_dict[\"model\"], \n",
    "                #                          artifact_path=\"\", \n",
    "                #                          registered_model_name=f\"model_{epoch}\",\n",
    "                #                          input_example=data[\"train\"][\"X\"][0,:,:].cpu().numpy())\n",
    "                \n",
    "                \n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "            \n",
    "            if verbose:\n",
    "                print()\n",
    "        \n",
    "        mlflow.log_metrics({ \"best_train_score\": best[\"train\"], \"best_val_score\": best[\"val\"], \"best_test_score\": best[\"test\"], \n",
    "                              \"best_epoch\": best[\"epoch\"] })\n",
    "        if verbose:\n",
    "            print('\\n\\nResult:')\n",
    "            print(best)\n",
    "    return best\n",
    "\n",
    "model_dict, data = prepare_model(data_prep, config=CONFIG | hyper_params)\n",
    "mlflow.set_experiment(f\"CMI LSTM Experiment {pd.Timestamp.now()}\")\n",
    "train(model_dict, data, CONFIG | hyper_params, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick grid search \n",
    "hyper_params = {\n",
    "    \"lstm_layers\": 1,\n",
    "    \"hidden_size\": 32,\n",
    "    'dropout': 0.1,\n",
    "    \"learning_rate\": 2e-3, \n",
    "    \"weight_decay\": 3e-4,\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"lstm_layers\": [1,2,4,8,16],\n",
    "    \"hidden_size\": [32, 64, 128, 256],\n",
    "    \"dropout\": [0, 0.1, 0.25, 0.5],\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3]\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(f\"CMI LSTM Gridsearch {pd.Timestamp.now()}\")\n",
    "gs_results = pd.DataFrame()\n",
    "\n",
    "for params in tqdm(ParameterGrid(param_grid)):\n",
    "    hp_run = hyper_params.copy()\n",
    "    hp_run.update(params)\n",
    "    model_dict, data = prepare_model(data_prep, config=CONFIG | hp_run)\n",
    "    \n",
    "    final_scores = train(model_dict, data, CONFIG | hp_run, verbose=False)\n",
    "    hp_run.update(final_scores)\n",
    "    gs_results = pd.concat([gs_results, pd.DataFrame(hp_run, index=[0])], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lstm_layers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dropout",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight_decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "03c8ed5c-7c99-4db2-8643-0990fb4c5178",
       "rows": [
        [
         "0",
         "1",
         "256",
         "0.1",
         "0.001",
         "0.0003",
         "0.99790293238827",
         "0.7418729775516113",
         "0.6945253669909666",
         "41"
        ],
        [
         "0",
         "2",
         "256",
         "0.0",
         "0.001",
         "0.0003",
         "0.9277471174492549",
         "0.7411609532611284",
         "0.698364585545563",
         "19"
        ],
        [
         "0",
         "4",
         "128",
         "0.25",
         "0.001",
         "0.0003",
         "0.9409899592992825",
         "0.7375230383879743",
         "0.6929088519284984",
         "41"
        ],
        [
         "0",
         "2",
         "256",
         "0.5",
         "0.001",
         "0.0003",
         "0.9539207900726789",
         "0.7372162378060214",
         "0.7112937668580548",
         "23"
        ],
        [
         "0",
         "4",
         "256",
         "0.5",
         "0.001",
         "0.0003",
         "0.9440087021587087",
         "0.7366358806588604",
         "0.6809671280437634",
         "35"
        ],
        [
         "0",
         "4",
         "256",
         "0.25",
         "0.001",
         "0.0003",
         "0.9633990175053181",
         "0.7358485400872328",
         "0.7097993955315498",
         "37"
        ],
        [
         "0",
         "2",
         "128",
         "0.5",
         "0.001",
         "0.0003",
         "0.9745231652616577",
         "0.7355017688543888",
         "0.707982570862155",
         "44"
        ],
        [
         "0",
         "4",
         "128",
         "0.5",
         "0.001",
         "0.0003",
         "0.9203556579126775",
         "0.7336872748331077",
         "0.6980872347859255",
         "35"
        ],
        [
         "0",
         "4",
         "256",
         "0.0",
         "0.001",
         "0.0003",
         "0.9302099673121362",
         "0.733421922318148",
         "0.688682938467336",
         "30"
        ],
        [
         "0",
         "2",
         "256",
         "0.25",
         "0.001",
         "0.0003",
         "0.9511214401273091",
         "0.7332584115470513",
         "0.7031123583631836",
         "23"
        ],
        [
         "0",
         "2",
         "128",
         "0.1",
         "0.001",
         "0.0003",
         "0.934947018379546",
         "0.7307462065558599",
         "0.7021844268851527",
         "29"
        ],
        [
         "0",
         "2",
         "64",
         "0.5",
         "0.001",
         "0.0003",
         "0.9143818860228398",
         "0.7306683893337511",
         "0.7001974993032614",
         "36"
        ],
        [
         "0",
         "8",
         "256",
         "0.5",
         "0.001",
         "0.0003",
         "0.9556192676932145",
         "0.7303690224088124",
         "0.6895704376133499",
         "85"
        ],
        [
         "0",
         "8",
         "128",
         "0.5",
         "0.001",
         "0.0003",
         "0.9008962931876185",
         "0.7292723958938485",
         "0.6957923950581393",
         "81"
        ],
        [
         "0",
         "1",
         "256",
         "0.25",
         "0.001",
         "0.0003",
         "0.9811948768806127",
         "0.7290676342946385",
         "0.7014610364847881",
         "28"
        ],
        [
         "0",
         "2",
         "128",
         "0.25",
         "0.001",
         "0.0003",
         "0.9542283883178135",
         "0.7278348979871121",
         "0.6947275253030667",
         "29"
        ],
        [
         "0",
         "4",
         "256",
         "0.1",
         "0.001",
         "0.0003",
         "0.9409695819407312",
         "0.727301081133949",
         "0.7061687636961924",
         "26"
        ],
        [
         "0",
         "4",
         "128",
         "0.0",
         "0.001",
         "0.0003",
         "0.9424317604724335",
         "0.7268738894873823",
         "0.6932241486605601",
         "35"
        ],
        [
         "0",
         "2",
         "256",
         "0.1",
         "0.001",
         "0.0003",
         "0.9257931475885937",
         "0.7265876854718645",
         "0.6986377237354847",
         "19"
        ],
        [
         "0",
         "4",
         "64",
         "0.0",
         "0.001",
         "0.0003",
         "0.9476139162692678",
         "0.7252387447058557",
         "0.6917708237270358",
         "53"
        ],
        [
         "0",
         "2",
         "32",
         "0.5",
         "0.01",
         "0.0003",
         "0.8971685294074848",
         "0.7252122229528205",
         "0.6823154810122584",
         "56"
        ],
        [
         "0",
         "1",
         "256",
         "0.5",
         "0.001",
         "0.0003",
         "0.9749406095304042",
         "0.7247081866703213",
         "0.6968959037190048",
         "24"
        ],
        [
         "0",
         "1",
         "128",
         "0.5",
         "0.001",
         "0.0003",
         "0.921373254060579",
         "0.7238605026645621",
         "0.698712501268215",
         "19"
        ],
        [
         "0",
         "1",
         "256",
         "0.0",
         "0.001",
         "0.0003",
         "0.8931608184739244",
         "0.7237249633334248",
         "0.7042472688654797",
         "11"
        ],
        [
         "0",
         "4",
         "64",
         "0.1",
         "0.001",
         "0.0003",
         "0.8615241382379191",
         "0.7236954772643545",
         "0.6916761051049558",
         "29"
        ],
        [
         "0",
         "4",
         "64",
         "0.25",
         "0.001",
         "0.0003",
         "0.9187395946625888",
         "0.7233458388003855",
         "0.700672064622613",
         "44"
        ],
        [
         "0",
         "1",
         "128",
         "0.0",
         "0.001",
         "0.0003",
         "0.9844424617970212",
         "0.7230522180704582",
         "0.6950725607265189",
         "34"
        ],
        [
         "0",
         "1",
         "128",
         "0.1",
         "0.001",
         "0.0003",
         "0.9407220200901136",
         "0.722923308710485",
         "0.6967357670079719",
         "21"
        ],
        [
         "0",
         "4",
         "128",
         "0.25",
         "0.01",
         "0.0003",
         "0.8425571447636288",
         "0.7216458371932114",
         "0.6846201843307838",
         "50"
        ],
        [
         "0",
         "2",
         "64",
         "0.5",
         "0.01",
         "0.0003",
         "0.8673523880297402",
         "0.7215560710195124",
         "0.7047650609020573",
         "31"
        ],
        [
         "0",
         "2",
         "32",
         "0.25",
         "0.001",
         "0.0003",
         "0.8834094260355603",
         "0.7211170290202129",
         "0.6765424511974932",
         "54"
        ],
        [
         "0",
         "2",
         "128",
         "0.0",
         "0.001",
         "0.0003",
         "0.9132713754386887",
         "0.7196861754884312",
         "0.7009551994026132",
         "23"
        ],
        [
         "0",
         "4",
         "128",
         "0.1",
         "0.01",
         "0.0003",
         "0.8733741308104307",
         "0.7190974416605678",
         "0.6740668245505004",
         "44"
        ],
        [
         "0",
         "2",
         "64",
         "0.25",
         "0.001",
         "0.0003",
         "0.9067731269594725",
         "0.718573740811265",
         "0.6867407240671562",
         "37"
        ],
        [
         "0",
         "4",
         "64",
         "0.5",
         "0.001",
         "0.0003",
         "0.8806205686751518",
         "0.718262748307673",
         "0.6921002509034674",
         "36"
        ],
        [
         "0",
         "4",
         "128",
         "0.1",
         "0.001",
         "0.0003",
         "0.8470471573761877",
         "0.7175990819170324",
         "0.6967349801316621",
         "16"
        ],
        [
         "0",
         "2",
         "64",
         "0.0",
         "0.001",
         "0.0003",
         "0.8996006521210852",
         "0.7170087528449678",
         "0.6771854514686438",
         "28"
        ],
        [
         "0",
         "4",
         "32",
         "0.0",
         "0.01",
         "0.0003",
         "0.8542238433659998",
         "0.7164421022263792",
         "0.6825046892914213",
         "49"
        ],
        [
         "0",
         "2",
         "64",
         "0.1",
         "0.001",
         "0.0003",
         "0.9065565189815883",
         "0.7135508933335737",
         "0.6916497769779766",
         "30"
        ],
        [
         "0",
         "4",
         "256",
         "0.25",
         "0.01",
         "0.0003",
         "0.8553314865207166",
         "0.7127544851929082",
         "0.6831372595517687",
         "45"
        ],
        [
         "0",
         "1",
         "128",
         "0.25",
         "0.001",
         "0.0003",
         "0.9512162612988373",
         "0.7125742914711186",
         "0.6947448463013226",
         "23"
        ],
        [
         "0",
         "2",
         "64",
         "0.25",
         "0.01",
         "0.0003",
         "0.8694886827992371",
         "0.7125381880010889",
         "0.6901543023803947",
         "34"
        ],
        [
         "0",
         "2",
         "128",
         "0.25",
         "0.01",
         "0.0003",
         "0.8946645149347205",
         "0.7111167173880191",
         "0.6857026262708551",
         "36"
        ],
        [
         "0",
         "4",
         "32",
         "0.5",
         "0.01",
         "0.0003",
         "0.8416781970544338",
         "0.7106218851360575",
         "0.6701963892015519",
         "69"
        ],
        [
         "0",
         "4",
         "64",
         "0.0",
         "0.01",
         "0.0003",
         "0.8601782265180185",
         "0.710512253878941",
         "0.6780949023863365",
         "43"
        ],
        [
         "0",
         "2",
         "32",
         "0.25",
         "0.01",
         "0.0003",
         "0.8852615367065438",
         "0.7093052012842248",
         "0.6878984565648394",
         "41"
        ],
        [
         "0",
         "2",
         "32",
         "0.5",
         "0.001",
         "0.0003",
         "0.863573749258013",
         "0.7092884767044728",
         "0.6767218364444603",
         "54"
        ],
        [
         "0",
         "1",
         "64",
         "0.1",
         "0.001",
         "0.0003",
         "0.9788825631875936",
         "0.7087847667114313",
         "0.6873003944176379",
         "58"
        ],
        [
         "0",
         "4",
         "64",
         "0.5",
         "0.01",
         "0.0003",
         "0.7847171543645272",
         "0.7077180165844776",
         "0.6611442296364058",
         "51"
        ],
        [
         "0",
         "4",
         "32",
         "0.1",
         "0.01",
         "0.0003",
         "0.8016851466544667",
         "0.707221434370465",
         "0.6960661027735094",
         "34"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 240
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.997903</td>\n",
       "      <td>0.741873</td>\n",
       "      <td>0.694525</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.927747</td>\n",
       "      <td>0.741161</td>\n",
       "      <td>0.698365</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.940990</td>\n",
       "      <td>0.737523</td>\n",
       "      <td>0.692909</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.953921</td>\n",
       "      <td>0.737216</td>\n",
       "      <td>0.711294</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.944009</td>\n",
       "      <td>0.736636</td>\n",
       "      <td>0.680967</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.381525</td>\n",
       "      <td>0.394450</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.394450</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.409881</td>\n",
       "      <td>0.394450</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.396385</td>\n",
       "      <td>0.394378</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.349202</td>\n",
       "      <td>0.394378</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lstm_layers  hidden_size  dropout  learning_rate  weight_decay     train  \\\n",
       "0             1          256     0.10          0.001        0.0003  0.997903   \n",
       "0             2          256     0.00          0.001        0.0003  0.927747   \n",
       "0             4          128     0.25          0.001        0.0003  0.940990   \n",
       "0             2          256     0.50          0.001        0.0003  0.953921   \n",
       "0             4          256     0.50          0.001        0.0003  0.944009   \n",
       "..          ...          ...      ...            ...           ...       ...   \n",
       "0             8          256     0.50          0.100        0.0003  0.381525   \n",
       "0            16          256     0.50          0.001        0.0003  0.412665   \n",
       "0             8          256     0.50          0.010        0.0003  0.409881   \n",
       "0             8          128     0.00          0.100        0.0003  0.396385   \n",
       "0            16          256     0.50          0.100        0.0003  0.349202   \n",
       "\n",
       "         val      test  epoch  \n",
       "0   0.741873  0.694525     41  \n",
       "0   0.741161  0.698365     19  \n",
       "0   0.737523  0.692909     41  \n",
       "0   0.737216  0.711294     23  \n",
       "0   0.736636  0.680967     35  \n",
       "..       ...       ...    ...  \n",
       "0   0.394450  0.393623      5  \n",
       "0   0.394450  0.393623      0  \n",
       "0   0.394450  0.393623      4  \n",
       "0   0.394378  0.393623      2  \n",
       "0   0.394378  0.393623      2  \n",
       "\n",
       "[240 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.sort_values(by=[\"val\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    \"lstm_layers\": 2,\n",
    "    \"hidden_size\": 256,\n",
    "    'dropout': 0.5,\n",
    "    \"learning_rate\": 0.001, \n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"n_epochs\": 23,\n",
    "    \"patience\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi-behavior-sensor-data (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
